{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\harsh\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\harsh\\anaconda3\\lib\\site-packages (4.3.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from gensim) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from gensim) (1.10.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Collecting FuzzyTM>=0.4.0 (from gensim)\n",
      "  Obtaining dependency information for FuzzyTM>=0.4.0 from https://files.pythonhosted.org/packages/2d/30/074bac7a25866a2807c1005c7852c0139ac22ba837871fc01f16df29b9dc/FuzzyTM-2.0.9-py3-none-any.whl.metadata\n",
      "  Downloading FuzzyTM-2.0.9-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from FuzzyTM>=0.4.0->gensim) (2.2.0)\n",
      "Collecting pyfume (from FuzzyTM>=0.4.0->gensim)\n",
      "  Obtaining dependency information for pyfume from https://files.pythonhosted.org/packages/ed/ea/a3b120e251145dcdb10777f2bc5f18b1496fd999d705a178c1b0ad947ce1/pyFUME-0.3.4-py3-none-any.whl.metadata\n",
      "  Downloading pyFUME-0.3.4-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2024.1)\n",
      "Collecting numpy>=1.18.5 (from gensim)\n",
      "  Obtaining dependency information for numpy>=1.18.5 from https://files.pythonhosted.org/packages/d8/ec/ebef2f7d7c28503f958f0f8b992e7ce606fb74f9e891199329d5f5f87404/numpy-1.24.4-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading numpy-1.24.4-cp311-cp311-win_amd64.whl.metadata (5.6 kB)\n",
      "Collecting simpful==2.12.0 (from pyfume->FuzzyTM>=0.4.0->gensim)\n",
      "  Obtaining dependency information for simpful==2.12.0 from https://files.pythonhosted.org/packages/9d/0e/aebc2fb0b0f481994179b2ee2b8e6bbf0894d971594688c018375e7076ea/simpful-2.12.0-py3-none-any.whl.metadata\n",
      "  Downloading simpful-2.12.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting fst-pso==1.8.1 (from pyfume->FuzzyTM>=0.4.0->gensim)\n",
      "  Downloading fst-pso-1.8.1.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pandas (from FuzzyTM>=0.4.0->gensim)\n",
      "  Obtaining dependency information for pandas from https://files.pythonhosted.org/packages/da/6d/1235da14daddaa6e47f74ba0c255358f0ce7a6ee05da8bf8eb49161aa6b5/pandas-1.5.3-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading pandas-1.5.3-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Collecting miniful (from fst-pso==1.8.1->pyfume->FuzzyTM>=0.4.0->gensim)\n",
      "  Downloading miniful-0.0.6.tar.gz (2.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\harsh\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->FuzzyTM>=0.4.0->gensim) (1.16.0)\n",
      "Downloading FuzzyTM-2.0.9-py3-none-any.whl (31 kB)\n",
      "Downloading pyFUME-0.3.4-py3-none-any.whl (60 kB)\n",
      "   ---------------------------------------- 0.0/60.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 60.3/60.3 kB ? eta 0:00:00\n",
      "Downloading numpy-1.24.4-cp311-cp311-win_amd64.whl (14.8 MB)\n",
      "   ---------------------------------------- 0.0/14.8 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/14.8 MB 11.3 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 1.1/14.8 MB 11.1 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.5/14.8 MB 10.7 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.6/14.8 MB 10.0 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 2.1/14.8 MB 9.0 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 2.4/14.8 MB 8.6 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 2.5/14.8 MB 8.5 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 2.5/14.8 MB 8.5 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.7/14.8 MB 6.4 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 3.4/14.8 MB 7.2 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 3.8/14.8 MB 7.4 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 4.1/14.8 MB 7.3 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 4.4/14.8 MB 7.2 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 4.7/14.8 MB 7.2 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 5.0/14.8 MB 7.1 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 5.3/14.8 MB 7.1 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 5.6/14.8 MB 7.0 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 5.9/14.8 MB 7.0 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 6.0/14.8 MB 7.0 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 6.5/14.8 MB 6.9 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 6.8/14.8 MB 6.9 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 7.1/14.8 MB 6.8 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 7.4/14.8 MB 6.8 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 7.6/14.8 MB 6.8 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 7.9/14.8 MB 6.8 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 8.2/14.8 MB 6.8 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 8.5/14.8 MB 6.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 8.8/14.8 MB 6.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 9.1/14.8 MB 6.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 9.4/14.8 MB 6.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 9.7/14.8 MB 6.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 10.0/14.8 MB 6.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 10.3/14.8 MB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 10.6/14.8 MB 6.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 10.9/14.8 MB 6.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 11.2/14.8 MB 6.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 11.5/14.8 MB 6.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 11.8/14.8 MB 6.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.0/14.8 MB 6.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 12.3/14.8 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 12.6/14.8 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 12.9/14.8 MB 6.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 13.2/14.8 MB 6.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 13.5/14.8 MB 6.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 13.8/14.8 MB 6.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.1/14.8 MB 6.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.4/14.8 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.7/14.8 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.8/14.8 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.8/14.8 MB 6.2 MB/s eta 0:00:00\n",
      "Downloading pandas-1.5.3-cp311-cp311-win_amd64.whl (10.3 MB)\n",
      "   ---------------------------------------- 0.0/10.3 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.2/10.3 MB 6.3 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.7/10.3 MB 8.4 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.1/10.3 MB 8.8 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.4/10.3 MB 8.2 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.7/10.3 MB 7.7 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.9/10.3 MB 7.5 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.3/10.3 MB 7.3 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.6/10.3 MB 7.2 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 2.9/10.3 MB 7.1 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.2/10.3 MB 7.0 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 3.5/10.3 MB 6.9 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 3.8/10.3 MB 6.9 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 4.1/10.3 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 4.3/10.3 MB 6.8 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 4.6/10.3 MB 6.8 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 4.9/10.3 MB 6.7 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 5.2/10.3 MB 6.7 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 5.5/10.3 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 5.8/10.3 MB 6.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.1/10.3 MB 6.6 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 6.4/10.3 MB 6.6 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 6.7/10.3 MB 6.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.0/10.3 MB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.3/10.3 MB 6.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 7.6/10.3 MB 6.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 7.9/10.3 MB 6.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.2/10.3 MB 6.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.5/10.3 MB 6.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 8.7/10.3 MB 6.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.0/10.3 MB 6.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.3/10.3 MB 6.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.6/10.3 MB 6.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.9/10.3 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.2/10.3 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.3/10.3 MB 6.4 MB/s eta 0:00:00\n",
      "Downloading simpful-2.12.0-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: fst-pso, miniful\n",
      "  Building wheel for fst-pso (setup.py): started\n",
      "  Building wheel for fst-pso (setup.py): finished with status 'done'\n",
      "  Created wheel for fst-pso: filename=fst_pso-1.8.1-py3-none-any.whl size=20448 sha256=80edf308703c7351ef20603cee8c7db3462a68715053b8b18c47e6f92e9fa9e8\n",
      "  Stored in directory: c:\\users\\harsh\\appdata\\local\\pip\\cache\\wheels\\69\\f5\\e5\\18ad53fe1ed6b2af9fad05ec052e4acbac8e92441df44bad2e\n",
      "  Building wheel for miniful (setup.py): started\n",
      "  Building wheel for miniful (setup.py): finished with status 'done'\n",
      "  Created wheel for miniful: filename=miniful-0.0.6-py3-none-any.whl size=3522 sha256=cc218676f2557d8a062b61b8607d5f3725232bbd5d83839599414906fce495fe\n",
      "  Stored in directory: c:\\users\\harsh\\appdata\\local\\pip\\cache\\wheels\\9d\\ff\\2f\\afe4cd56f47de147407705626517d68bea0f3b74eb1fb168e6\n",
      "Successfully built fst-pso miniful\n",
      "Installing collected packages: numpy, pandas, simpful, miniful, fst-pso, pyfume, FuzzyTM\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.3\n",
      "    Uninstalling numpy-1.24.3:\n",
      "      Successfully uninstalled numpy-1.24.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\harsh\\\\anaconda3\\\\Lib\\\\site-packages\\\\~umpy\\\\core\\\\_multiarray_tests.cp311-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3709,
     "status": "ok",
     "timestamp": 1700375915797,
     "user": {
      "displayName": "Harish Bapat",
      "userId": "01261412703411895454"
     },
     "user_tz": -330
    },
    "id": "Il4OWhgbHbJz",
    "outputId": "062cd898-50f6-469f-bfd9-3864cc5c3f5c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\harsh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\harsh\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted word: [('love', 0.25000066)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenize the text into words\n",
    "    tokens = word_tokenize(text.lower())\n",
    "\n",
    "    # Remove stopwords and punctuation\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word.isalpha() and word not in stop_words and word not in string.punctuation]\n",
    "\n",
    "    return tokens\n",
    "\n",
    "# Sample text for training the CBOW model\n",
    "text = \"Hi my name is Harish.I love to read.I love to sing.Thats all folks\"\n",
    "\n",
    "# Preprocess the text\n",
    "tokens = preprocess_text(text)\n",
    "\n",
    "# Create training data with context and target word\n",
    "training_data = []\n",
    "context_size = 2  # Adjust the context size as needed\n",
    "\n",
    "for i in range(context_size, len(tokens) - context_size):\n",
    "    context = tokens[i - context_size : i] + tokens[i + 1 : i + 1 + context_size]\n",
    "    target = tokens[i]\n",
    "    training_data.append(context + [target])  # Combine context and target into a single list\n",
    "\n",
    "# Define the CBOW model using Word2Vec\n",
    "model_cbow = Word2Vec(sentences=training_data, vector_size=500, window=context_size, sg=0, min_count=1, workers=4)\n",
    "\n",
    "# Training the CBOW model\n",
    "model_cbow.train(training_data, total_examples=len(training_data), epochs=20)\n",
    "\n",
    "# Given two previous and two latter words, predict the target word\n",
    "previous_words = [\"name\", \"Harish\"]\n",
    "latter_words = [\"sing\", \"folks\"]\n",
    "\n",
    "# Use the predict_output_word function from gensim.models.word2vec module\n",
    "predicted_word = model_cbow.predict_output_word(previous_words + latter_words, topn=1)\n",
    "\n",
    "print(f\"Predicted word: {predicted_word}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 549,
     "status": "ok",
     "timestamp": 1700296496980,
     "user": {
      "displayName": "Harish Bapat",
      "userId": "01261412703411895454"
     },
     "user_tz": -330
    },
    "id": "MJ8u2oURHde5",
    "outputId": "f6f8ce85-6f6a-48f6-9480-4af74ef36edb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words most similar to '[('love', 0.25000066)]':\n",
      "name: 0.00685887411236763\n",
      "hi: -0.04485169053077698\n",
      "folks: -0.05462679639458656\n"
     ]
    }
   ],
   "source": [
    "similar_words = model_cbow.wv.most_similar(predicted_word, topn=5)\n",
    "\n",
    "print(f\"Words most similar to '{predicted_word}':\")\n",
    "for word, similarity in similar_words:\n",
    "    print(f\"{word}: {similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 390,
     "status": "ok",
     "timestamp": 1700282105226,
     "user": {
      "displayName": "Harish Bapat",
      "userId": "01261412703411895454"
     },
     "user_tz": -330
    },
    "id": "d1cmIhS9H80x",
    "outputId": "2e9e78d3-1b2f-458d-c472-bbb04d1453a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi', 'name', 'love', 'love', 'folks']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
